<!DOCTYPE html><html lang="en"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1"><title>Past Art Vol 2: About a Year of It | Blog</title><meta name="description" content="Things i gone and done "><meta itemprop="name" content="Jonny Saunders"><meta itemprop="description" content="Collecting the scraps from about a year of wasting my time"><meta itemprop="image" content="https://jon-e.net/blog/blog/assets/images/artvol2/endless_love.png"><meta property="og:url" content="https://jon-e.net/blog/2020/03/29/Past-Art-Vol-2/"><meta property="og:type" content="website"><meta property="og:title" content="Past Art Vol 2: About a Year of It | Blog"><meta property="og:site_name" content="Blog"><meta property="og:description" content="Collecting the scraps from about a year of wasting my time"><meta property="og:image" content="https://jon-e.net/blog/blog/assets/images/artvol2/endless_love.png"><meta name="twitter:url" content="https://jon-e.net/blog/2020/03/29/Past-Art-Vol-2/"><meta name="twitter:url" content=""><meta name="twitter:card" content="summary"><meta name="twitter:title" content="Past Art Vol 2: About a Year of It | Blog"><meta name="twitter:site" content="Blog"><meta name="twitter:description" content="Collecting the scraps from about a year of wasting my time"><meta name="twitter:creator" content="@json_dirs"><meta property="twitter:image" content="https://jon-e.net/blog/blog/assets/images/artvol2/endless_love.png"><link rel="icon" type="image/x-icon" href="/blog/assets/images/favicon.ico"> <script src="https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.min.js"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css" /> <script src="https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js"></script><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/css/bootstrap.min.css" integrity="sha384-MCw98/SFnGE8fJT3GXwEOngsV7Zt27NXFoaoApmYm81iuXoPkFOJwJ8ERdknLPMO" crossorigin="anonymous"><link rel="stylesheet" href="https://cdn.rawgit.com/afeld/bootstrap-toc/v1.0.0/dist/bootstrap-toc.min.css"> <script src="https://cdn.rawgit.com/afeld/bootstrap-toc/v1.0.0/dist/bootstrap-toc.min.js"></script><link rel="stylesheet" href="/blog/assets/css/app.min.css"><style> .hljs{display:block;overflow-x:auto;padding:0.5em;background:#23241f}.hljs,.hljs-tag,.hljs-subst{color:#f8f8f2}.hljs-strong,.hljs-emphasis{color:#a8a8a2}.hljs-bullet,.hljs-quote,.hljs-number,.hljs-regexp,.hljs-literal,.hljs-link{color:#ae81ff}.hljs-code,.hljs-title,.hljs-section,.hljs-selector-class{color:#a6e22e}.hljs-strong{font-weight:bold}.hljs-emphasis{font-style:italic}.hljs-keyword,.hljs-selector-tag,.hljs-name,.hljs-attr{color:#f92672}.hljs-symbol,.hljs-attribute{color:#66d9ef}.hljs-params,.hljs-class .hljs-title{color:#f8f8f2}.hljs-string,.hljs-type,.hljs-built_in,.hljs-builtin-name,.hljs-selector-id,.hljs-selector-attr,.hljs-selector-pseudo,.hljs-addition,.hljs-variable,.hljs-template-variable{color:#e6db74}.hljs-comment,.hljs-deletion,.hljs-meta{color:#75715e}</style><script async src="https://www.googletagmanager.com/gtag/js?id=UA-127799940-1"></script> <script> window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-127799940-1'); </script><link rel="alternate" type="application/rss+xml" title="Blog" href="/blog/feed.xml"><link rel="canonical" href="/blog/2020/03/29/Past-Art-Vol-2/"></head><body id="past-art-vol-2-about-a-year-of-it" class="post-layout"><header class="header"> <a class="header__title" href="https://jon-e.net/blog/">Blog</a><nav><ul class="header__list"><li><a href="/blog/">Stories</a></li><li><span class="popup__open">Contact</span></li></ul></nav></header><main class="💈"><div class="post"><article itemprop="blogPost" itemscope itemtype="http://schema.org/BlogPosting"><div class="post__header section-padding--double"><div class="grid-small"><h2 itemprop="name headline">Past Art Vol 2: About a Year of It</h2><time class="post__date" datetime="2020-03-29T00:00:00-07:00" itemprop="datePublished">29 Mar 2020</time></div></div><div class="post__img"><div><figure class="absolute-bg" style="background-image: url('/blog/assets/images/artvol2/endless_love.png');"></figure></div></div><div class="post-container"><div class="post__content section-padding" id="markdown" itemprop="articleBody"><p>There’s a folder on my computer that is named <code class="highlighter-rouge">stupid_bullshit_projects</code> that continually fills up with the things that i make and never end up telling anyone about. It is never in a hurry to get filled up, and so I add to it in limps and startles.</p><p>This last year was an especially good year for <code class="highlighter-rouge">stupid_bullshit_projects</code> because I was doing anything I could to distract myself from some heartbreak that was unbearable almost all of the time. Don’t close the tab just yet, I’m mostly past it now, most of what’s left is just reflecting.</p><p>I wanted to try to remember some of the things that I make, because maybe that would make them feel more real. Visual art came into my life very late, and I haven’t quite shaken the feeling that I’m not invited. I’ve been led to believe that visual artists have a medium, and I don’t really have the discipline to maintain one of those. Music has instruments and genres, but since synthesis and hip-hop have made a mess of those they never felt quite so intimidating.</p><p>Not really expecting anyone but me to get much joy out of them, but here are some things that I’ve made because I sorta had to.</p><h1 id="with-music">With Music</h1><p>Music is subtly but potently visual to me, and while I haven’t quite gotten to the point that I can make video with my own music, I do love making videos to other people’s music.</p><h2 id="murmuration-20200210">Murmuration (2020.02.10)</h2><p>The sun was just starting to come back to Eugene and I was putting some periods on some memories. Things were bulging and shifting and nothing really felt settled. There were some nice winter sunsets though.</p><p>This is a simple lil glitch, a pulsed p-frame duplication with an RGB channel shift. The blooming effect from 00:48 to 00:54 was what I was itching for. Most of the beauty comes from the source video, a starling murmuration.</p><p>Music: Laura Jean Anderson - thinkin bout you</p><p><a data-fancybox="" href="https://vimeo.com/390663030" vidid="390663030" class="vimeo-vid"> </a></p><h2 id="thao--the-get-down-stay-down---a-man-alive-20200127">Thao &amp; The Get Down Stay Down - A Man Alive (2020.01.27)</h2><p>A) I love this album, and B) it was saying exactly what I was feeling at the time. These were three songs that I thought summed my bittersweet ass up relatively neatly <em>(you know I’m so easy to find, you won’t come get your girl)</em>.</p><p>Technically very simple, rgb shift and a bunch of manual time warping &amp; splicing.</p><h3 class="no_toc" id="endless-love">Endless Love</h3><p><a data-fancybox="" href="https://vimeo.com/391770842" vidid="391770842" class="vimeo-vid"> </a></p><h3 class="no_toc" id="departure">Departure</h3><p><a data-fancybox="" href="https://vimeo.com/391765834" vidid="391765834" class="vimeo-vid"> </a></p><h3 class="no_toc" id="guts">Guts</h3><p><a data-fancybox="" href="https://vimeo.com/391768918" vidid="391768918" class="vimeo-vid"> </a></p><h2 class="no_toc" id="guillotine-20191202">Guillotine (2019.12.02)</h2><p>Someone I like on Twitter posted some video using <a href="https://github.com/abedavis/visbeat">visbeat</a> and so I made a bunch of deathgrips memes. this was my favorite one.</p><p>video: <a href="https://www.youtube.com/watch?v=CgHiSwR05VM">Arthur Ganson, The First Noble Truth</a></p><p><a data-fancybox="" href="https://vimeo.com/390680486" vidid="390680486" class="vimeo-vid"> </a></p><h2 id="nick-hakim---miss-chew-20191102">Nick Hakim - Miss Chew (2019.11.02)</h2><p>We had a party at my house and I had taken some MDMA that had some little extra kick in it that made my eyeballs spin out of my sockets. When I could focus my vision again I started synthesizing video to project over the dancefloor i mean our living room. A housemate of mine that loves horror movies had suggested we watch Nosferatu the night before so I was using that as some of the source material. Burned a bunch of music into a good place in my heart.</p><p>The next day I had a sentimental hangover, my heart was vacant and I was still stumbling over the last hurdles before acceptance. Mostly I was full of missing. Another simple p-frame duplication with a little random hex noise thrown into the encoded video stream before it gets decoded.</p><p><a data-fancybox="" href="https://vimeo.com/390679861" vidid="390679861" class="vimeo-vid"> </a></p><h2 id="tirzah---affection-20191022">Tirzah - Affection (2019.10.22)</h2><p>I was in an unexpected new depth in a hopeless argument with my heart, bargaining with my memories and promising to change, and working on a bunch of computer vision code. I started shooting video as a demo of the code for my collaborators, but got lost in its sort of numbing sparseness.</p><p>I can’t really describe the process for this one – the source video is some computer-vision glitch that I just kept pushing my thumb into until it looked right. Then I lost a few days layering and cutting the clips until it was done.</p><p><a data-fancybox="" href="https://vimeo.com/401774066" vidid="401774066" class="vimeo-vid"> </a></p><h1 id="webzones">Webzones</h1><h2 id="perlin-particles-20200119">Perlin Particles (2020.01.19)</h2><p>A friend and mentor who is a recently-minted PI asked me to make her a lab website. This ended up being the central design element, but along the way I made a version just to play with.</p><p>Particles on 2D perlin noise. I think this one does better without documentation, just play with the slideys and see.</p><p><a data-fancybox="" data-type="iframe" href="/projects/perlin/index.html" class="iframe-preview">Open demo</a></p><h2 id="how-to-never-get-hired-for-any-job-pt-2-20191219">how to never get hired for any job pt 2. (2019.12.19)</h2><p>My <a href="https://jon-e.net/about/">about me</a> page is sorta an anti-about me page… while I was still getting used to having to be professional all the time it seemed super weird to me to have an entire page just describing yourself. So right now the page just indeciperably refers to my feelings about having people look at an “about me” page about me. I was trying to fix that and got lost along the way. The idea was to have my information passing by on these mountains and to make the user move their mouse to make certain regions lie flat long enough to read. I decided that sucks and that I should just make a real one, but inner me is holding up the timeline.</p><p><a data-fancybox="" data-type="iframe" href="/about/terrain.html" class="iframe-preview">Open demo</a></p><h2 id="speeding-atlas-20191115">Speeding Atlas (2019.11.15)</h2><p>If you combine the <a href="https://openpolicing.stanford.edu/data/">Stanford Open Policing Project</a> data with transportation department road use data and assume that speeding is roughly equally likely on all roads, you can make a map of the roads that you are more or less likely to get a speeding ticket on. This is a map for just Washington state because other states have less data available and beacause I realized what a huge waste of time this was.</p><p>Map made with <a href="https://rstudio.github.io/leaflet/">leaflet</a> in R.</p><p><a data-fancybox="" data-type="iframe" href="/projects/traffic/index.html" class="iframe-preview">Open demo</a></p><h1 id="alternative-media">~alternative media~</h1><h2 id="instagram-filters-20200119">instagram filters (2020.01.19)</h2><p>I found out they let <em>just anyone</em> make instagram filters, and their platform is actually really lovely. I just made a few, not very good but i laughed a few times.</p><p>First a classic tinyface just to see how it works:</p><video controls="" preload="none" style="max-height: 70vh;"> <source src="/blog/assets/images/artvol2/tinyface_2.mp4" type="video/mp4" /> Your browser doesn't support HTML5 video tag. </video><p>The I made a Mitt Romney face (and my housemate used it to watch Sex and the City):</p><video controls="" preload="none" style="max-height: 70vh;"> <source src="/blog/assets/images/artvol2/mitt.mp4" type="video/mp4" /> Your browser doesn't support HTML5 video tag. </video><p>And then Hank. Took a lot to make the 3d model of the head and face work together, and to add a lil cherry on top you get a coupla catch phrases when u open your mouth.</p><video controls="" preload="none" style="max-height: 70vh;"> <source src="/blog/assets/images/artvol2/hank.mp4" type="video/mp4" /> Your browser doesn't support HTML5 video tag. </video><h2 id="autopotterotica-20200101">Autopotterotica (2020.01.01)</h2><p>um.</p><p>Where to start with this one.</p><p>Fanfiction is, at least to me, one of the strangest but most beautiful human instincts. The raw diversity <em>and volume</em> of wish-fulfillment that happens within the bounds of fanfiction positively fucks up the elevation of my jaw. So I thought it might be interesting to have a neural net generate some.</p><p>It turns out fanfiction.net is the largest natural language text corpus that I’ve ever been able to find by orders of magnitude – 1.5T compressed text, hundreds or thousands of wikipedias. The scrape took ~7 weeks of 24/7 scraping.</p><p>I’ve never written fanfiction, but I did read a lot of experimental erotica at backyard poetry readings in college, and it quickly became clear what the neural net wanted to write.</p><p>These stories are all 100% neural-net generated (finetuned GPT-2) text. They are about 50% fully-random initializations and 50% initializations with seed text, but it didn’t take much. The only editing I do is cutting repetetive text, formatting into paragraphs, and minor fixes to punctuation – I don’t add anything or change its order. These are just a sample, I’m looking to finish the book during this great pause.</p><p>So, first, the scraping code for those for whom it would be useful, and then the smut for which I request you not put me in jail for.</p><p><code class="highlighter-rouge">list_stories.py</code> - get a list of all available stories and their metadata</p><figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">from</span> <span class="nn">bs4</span> <span class="kn">import</span> <span class="n">BeautifulSoup</span> <span class="k">as</span> <span class="n">bs</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span><span class="p">,</span> <span class="n">trange</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">tables</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">pdb</span>
<span class="kn">import</span> <span class="nn">traceback</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">multiprocessing</span> <span class="k">as</span> <span class="n">mp</span>

<span class="kn">import</span> <span class="nn">argparse</span>



<span class="n">BROWSE_FANFIC</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">'anime'</span><span class="p">:</span> <span class="s">'https://www.fanfiction.net/anime/'</span><span class="p">,</span>
    <span class="s">'book'</span><span class="p">:</span>  <span class="s">'https://www.fanfiction.net/book/'</span><span class="p">,</span>
    <span class="s">'cartoon'</span><span class="p">:</span> <span class="s">'https://www.fanfiction.net/cartoon/'</span><span class="p">,</span>
    <span class="s">'comic'</span><span class="p">:</span> <span class="s">'https://www.fanfiction.net/comic/'</span><span class="p">,</span>
    <span class="s">'game'</span><span class="p">:</span> <span class="s">'https://www.fanfiction.net/game/'</span><span class="p">,</span>
    <span class="s">'misc'</span><span class="p">:</span> <span class="s">'https://www.fanfiction.net/misc/'</span><span class="p">,</span>
    <span class="s">'play'</span><span class="p">:</span> <span class="s">'https://www.fanfiction.net/play/'</span><span class="p">,</span>
    <span class="s">'movie'</span><span class="p">:</span> <span class="s">'https://www.fanfiction.net/movie/'</span><span class="p">,</span>
    <span class="s">'tv'</span><span class="p">:</span> <span class="s">'https://www.fanfiction.net/tv/'</span>
<span class="p">}</span>

<span class="k">def</span> <span class="nf">list_universes</span><span class="p">():</span>
    <span class="s">"""
    List all story universes available on fanfiction.net and the number of stories they have
    """</span>
    <span class="n">rows</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">fanfic_type</span><span class="p">,</span> <span class="n">browse_page</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">BROWSE_FANFIC</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">position</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>

        <span class="n">page</span> <span class="o">=</span> <span class="n">bs</span><span class="p">(</span><span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">browse_page</span><span class="p">)</span><span class="o">.</span><span class="n">content</span><span class="p">,</span> <span class="s">'lxml'</span><span class="p">)</span>
        <span class="n">link_groups</span> <span class="o">=</span> <span class="n">page</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="s">"list_output"</span><span class="p">)</span><span class="o">.</span><span class="n">find_all</span><span class="p">(</span><span class="s">'div'</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">link_groups</span><span class="p">,</span> <span class="n">position</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">link</span> <span class="o">=</span> <span class="n">l</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s">'a'</span><span class="p">)</span>
            <span class="n">story_num</span> <span class="o">=</span> <span class="n">l</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s">'span'</span><span class="p">)</span><span class="o">.</span><span class="n">text</span><span class="o">.</span><span class="n">lstrip</span><span class="p">(</span><span class="s">'('</span><span class="p">)</span><span class="o">.</span><span class="n">rstrip</span><span class="p">(</span><span class="s">')'</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">story_num</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s">'K'</span><span class="p">):</span>
                <span class="n">story_num</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">story_num</span><span class="o">.</span><span class="n">rstrip</span><span class="p">(</span><span class="s">'K'</span><span class="p">))</span><span class="o">*</span><span class="mi">1000</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">story_num</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">story_num</span><span class="p">)</span>
            <span class="n">rows</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">fanfic_type</span><span class="p">,</span> <span class="n">link</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="n">story_num</span><span class="p">,</span> <span class="s">'https://www.fanfiction.net'</span><span class="o">+</span><span class="n">link</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s">'href'</span><span class="p">)))</span>

    <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_records</span><span class="p">(</span><span class="n">rows</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">(</span><span class="s">'type'</span><span class="p">,</span> <span class="s">'universe'</span><span class="p">,</span> <span class="s">'n_stories'</span><span class="p">,</span> <span class="s">'url'</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">list_stories</span><span class="p">(</span><span class="n">row</span><span class="p">):</span>
    <span class="s">"""
    For a particular story universe, list all stories and return their metadata.

    Args:
        row (tables.Row): row containing metadata from list_universes()
    """</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">i</span><span class="p">,</span> <span class="n">row</span> <span class="o">=</span> <span class="n">row</span>
        <span class="c1"># FIXME: hardcoding base_dir
</span>        <span class="n">base_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getcwd</span><span class="p">(),</span> <span class="s">'stories'</span><span class="p">)</span>
        <span class="n">save_fn</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">base_dir</span><span class="p">,</span> <span class="n">row</span><span class="o">.</span><span class="n">universe</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s">'/'</span><span class="p">,</span><span class="s">'-'</span><span class="p">)</span><span class="o">+</span><span class="s">'.pck.gz'</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">save_fn</span><span class="p">):</span>
            <span class="k">return</span>

        <span class="n">stories</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">first_page</span> <span class="o">=</span> <span class="n">bs</span><span class="p">(</span><span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">row</span><span class="o">.</span><span class="n">url</span><span class="o">+</span><span class="s">"?&amp;srt=1&amp;r=10"</span><span class="p">)</span><span class="o">.</span><span class="n">content</span><span class="p">,</span> <span class="s">'lxml'</span><span class="p">)</span>


        <span class="c1"># find last page
</span>        <span class="k">try</span><span class="p">:</span>
            <span class="n">last_page_url</span> <span class="o">=</span> <span class="n">first_page</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s">'center'</span><span class="p">)</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s">'a'</span><span class="p">,</span> <span class="n">text</span><span class="o">=</span><span class="s">'Last'</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s">'href'</span><span class="p">)</span>
            <span class="n">last_page</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">last_page_url</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s">'&amp;p='</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="k">except</span> <span class="nb">AttributeError</span><span class="p">:</span>
            <span class="n">last_page</span> <span class="o">=</span> <span class="mi">1</span>

        <span class="c1"># get current process number to place progress bar
</span>        <span class="k">try</span><span class="p">:</span>
            <span class="n">current</span> <span class="o">=</span> <span class="n">mp</span><span class="o">.</span><span class="n">current_process</span><span class="p">()</span>
            <span class="n">tqdm_position</span> <span class="o">=</span> <span class="n">current</span><span class="o">.</span><span class="n">_identity</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">+</span><span class="mi">1</span>
        <span class="k">except</span><span class="p">:</span>
            <span class="n">tqdm_position</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="n">story_pbar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">position</span><span class="o">=</span><span class="n">tqdm_position</span><span class="p">,</span> <span class="n">total</span><span class="o">=</span><span class="n">row</span><span class="o">.</span><span class="n">n_stories</span><span class="p">)</span>

        <span class="c1"># iterate through pages listing stories and get their metadata
</span>        <span class="k">for</span> <span class="n">page_num</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">last_page</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">page_url</span> <span class="o">=</span> <span class="n">row</span><span class="o">.</span><span class="n">url</span> <span class="o">+</span> <span class="s">'?&amp;srt=1&amp;r=10&amp;p={}'</span><span class="o">.</span><span class="nb">format</span><span class="p">(</span><span class="n">page_num</span><span class="p">)</span>
            <span class="n">page</span> <span class="o">=</span> <span class="n">bs</span><span class="p">(</span><span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">page_url</span><span class="p">)</span><span class="o">.</span><span class="n">content</span><span class="p">,</span> <span class="s">'lxml'</span><span class="p">)</span>

            <span class="n">links</span> <span class="o">=</span> <span class="n">page</span><span class="o">.</span><span class="n">find_all</span><span class="p">(</span><span class="n">class_</span><span class="o">=</span><span class="s">'z-list'</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">links</span><span class="p">:</span>
                <span class="n">story_url</span> <span class="o">=</span> <span class="n">l</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="n">class_</span><span class="o">=</span><span class="s">'stitle'</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s">'href'</span><span class="p">)</span>
                <span class="n">story_id</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">story_url</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s">'/'</span><span class="p">)[</span><span class="mi">2</span><span class="p">])</span>
                <span class="n">story_name</span> <span class="o">=</span> <span class="n">l</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="n">class_</span><span class="o">=</span><span class="s">'stitle'</span><span class="p">)</span><span class="o">.</span><span class="n">text</span>
                <span class="n">story_url</span> <span class="o">=</span> <span class="s">'https://fanfiction.net'</span> <span class="o">+</span> <span class="n">story_url</span>

                <span class="n">stories</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">row</span><span class="o">.</span><span class="n">universe</span><span class="p">,</span> <span class="n">story_id</span><span class="p">,</span> <span class="n">story_url</span><span class="p">,</span> <span class="n">story_name</span><span class="p">))</span>
                <span class="n">story_pbar</span><span class="o">.</span><span class="n">update</span><span class="p">()</span>

        <span class="n">story_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_records</span><span class="p">(</span><span class="n">stories</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">(</span><span class="s">'universe'</span><span class="p">,</span> <span class="s">'id'</span><span class="p">,</span> <span class="s">'url'</span><span class="p">,</span> <span class="s">'name'</span><span class="p">))</span>
        <span class="n">story_df</span><span class="o">.</span><span class="n">to_pickle</span><span class="p">(</span><span class="n">save_fn</span><span class="p">,</span> <span class="n">compression</span><span class="o">=</span><span class="s">'gzip'</span><span class="p">)</span>
    <span class="k">except</span> <span class="nb">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
        <span class="n">pdb</span><span class="o">.</span><span class="n">set_trace</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">list_hp</span><span class="p">(</span><span class="n">url</span><span class="p">):</span>


    <span class="n">page</span> <span class="o">=</span> <span class="n">bs</span><span class="p">(</span><span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">)</span><span class="o">.</span><span class="n">content</span><span class="p">,</span> <span class="s">'lxml'</span><span class="p">)</span>

    <span class="n">links</span> <span class="o">=</span> <span class="n">page</span><span class="o">.</span><span class="n">find_all</span><span class="p">(</span><span class="n">class_</span><span class="o">=</span><span class="s">'z-list'</span><span class="p">)</span>
    <span class="n">stories</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">links</span><span class="p">:</span>
        <span class="n">story_url</span> <span class="o">=</span> <span class="n">l</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="n">class_</span><span class="o">=</span><span class="s">'stitle'</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s">'href'</span><span class="p">)</span>
        <span class="n">story_id</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">story_url</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s">'/'</span><span class="p">)[</span><span class="mi">2</span><span class="p">])</span>
        <span class="n">story_name</span> <span class="o">=</span> <span class="n">l</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="n">class_</span><span class="o">=</span><span class="s">'stitle'</span><span class="p">)</span><span class="o">.</span><span class="n">text</span>
        <span class="n">story_url</span> <span class="o">=</span> <span class="s">'https://fanfiction.net'</span> <span class="o">+</span> <span class="n">story_url</span>

        <span class="n">stories</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="s">'Harry Potter'</span><span class="p">,</span> <span class="n">story_id</span><span class="p">,</span> <span class="n">story_url</span><span class="p">,</span> <span class="n">story_name</span><span class="p">))</span>

    <span class="n">story_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_records</span><span class="p">(</span><span class="n">stories</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">(</span><span class="s">'universe'</span><span class="p">,</span> <span class="s">'id'</span><span class="p">,</span> <span class="s">'url'</span><span class="p">,</span> <span class="s">'name'</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">story_df</span>



<span class="k">def</span> <span class="nf">list_harry_potter</span><span class="p">():</span>
    <span class="n">pool</span> <span class="o">=</span> <span class="n">mp</span><span class="o">.</span><span class="n">Pool</span><span class="p">(</span><span class="mi">12</span><span class="p">)</span>

    <span class="n">base_url</span> <span class="o">=</span> <span class="s">'https://www.fanfiction.net/book/Harry-Potter/'</span>

    <span class="c1"># FIXME: hardcoding base_dir
</span>    <span class="n">base_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getcwd</span><span class="p">(),</span> <span class="s">'stories'</span><span class="p">)</span>

    <span class="n">save_fn</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">base_dir</span><span class="p">,</span> <span class="s">'Harry Potter'</span><span class="o">+</span><span class="s">'.pck.gz'</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">save_fn</span><span class="p">):</span>
        <span class="k">return</span>
    <span class="n">first_page</span> <span class="o">=</span> <span class="n">bs</span><span class="p">(</span><span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">base_url</span><span class="o">+</span><span class="s">"?&amp;srt=1&amp;r=10"</span><span class="p">)</span><span class="o">.</span><span class="n">content</span><span class="p">,</span> <span class="s">'lxml'</span><span class="p">)</span>


    <span class="c1"># find last page
</span>    <span class="k">try</span><span class="p">:</span>
        <span class="n">last_page_url</span> <span class="o">=</span> <span class="n">first_page</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s">'center'</span><span class="p">)</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s">'a'</span><span class="p">,</span> <span class="n">text</span><span class="o">=</span><span class="s">'Last'</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s">'href'</span><span class="p">)</span>
        <span class="n">last_page</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">last_page_url</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s">'&amp;p='</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">except</span> <span class="nb">AttributeError</span><span class="p">:</span>
        <span class="n">last_page</span> <span class="o">=</span> <span class="mi">1</span>

    <span class="n">page_urls</span> <span class="o">=</span> <span class="p">[</span><span class="n">base_url</span> <span class="o">+</span> <span class="s">'?&amp;srt=1&amp;r=10&amp;p={}'</span><span class="o">.</span><span class="nb">format</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">last_page</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span>

    <span class="n">pbar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">total</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">page_urls</span><span class="p">),</span> <span class="n">position</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="n">pdb</span><span class="o">.</span><span class="n">set_trace</span><span class="p">()</span>
    <span class="n">results</span> <span class="o">=</span> <span class="n">pool</span><span class="o">.</span><span class="n">imap_unordered</span><span class="p">(</span><span class="n">list_hp</span><span class="p">,</span> <span class="n">page_urls</span><span class="p">)</span>

    <span class="n">pages</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">results</span><span class="p">:</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">r</span><span class="o">.</span><span class="n">get</span><span class="p">()</span>
        <span class="n">pages</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
        <span class="n">pbar</span><span class="o">.</span><span class="n">update</span><span class="p">()</span>

    <span class="n">hp_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">pages</span><span class="p">)</span>
    <span class="n">hp_df</span><span class="o">.</span><span class="n">to_pickle</span><span class="p">(</span><span class="n">save_fn</span><span class="p">,</span> <span class="n">compression</span><span class="o">=</span><span class="s">"gzip"</span><span class="p">)</span>


<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">"__main__"</span><span class="p">:</span>
    <span class="n">parser</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">()</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s">'--universes'</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s">'location of the universes.json file that tracks which stories we need to reload'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s">'--stories'</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s">'location of stories directory - links to all stories'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s">'--list'</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s">'only list stories'</span><span class="p">)</span>
    <span class="n">args</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_args</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">universes</span><span class="p">:</span>
        <span class="n">universe_path</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">universes</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">universe_path</span> <span class="o">=</span> <span class="s">'universes.json'</span>

    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">stories</span><span class="p">:</span>
        <span class="n">story_path</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">stories</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">story_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getcwd</span><span class="p">(),</span><span class="s">'stories'</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">story_path</span><span class="p">):</span>
        <span class="n">os</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">story_path</span><span class="p">)</span>

    <span class="c1"># list universes, if we have a previously available universes file,
</span>    <span class="c1"># find universes that have more stories than we had last time.
</span>    <span class="n">universes</span> <span class="o">=</span> <span class="n">list_universes</span><span class="p">()</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">past_universes</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_json</span><span class="p">(</span><span class="n">universe_path</span><span class="p">)</span>
        <span class="n">universes</span> <span class="o">=</span> <span class="n">universes</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">universes</span><span class="o">.</span><span class="n">n_stories</span> <span class="o">&gt;</span> <span class="n">past_universes</span><span class="o">.</span><span class="n">n_stories</span><span class="p">,]</span>
    <span class="k">except</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="s">'</span><span class="se">\n</span><span class="s">couldnt load old universes directory, loading all</span><span class="se">\n</span><span class="s">'</span><span class="p">)</span>

    <span class="n">universes</span><span class="o">.</span><span class="n">to_json</span><span class="p">(</span><span class="n">universe_path</span><span class="p">)</span>

    <span class="c1"># start a pool of workers to list stories
</span>    <span class="n">pool</span> <span class="o">=</span> <span class="n">mp</span><span class="o">.</span><span class="n">Pool</span><span class="p">(</span><span class="mi">12</span><span class="p">)</span>
    <span class="c1">#
</span>    <span class="c1"># list_harry_potter()
</span>
    <span class="n">pbar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">total</span><span class="o">=</span><span class="n">universes</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">position</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="n">results</span> <span class="o">=</span> <span class="n">pool</span><span class="o">.</span><span class="n">imap_unordered</span><span class="p">(</span><span class="n">list_stories</span><span class="p">,</span> <span class="n">universes</span><span class="o">.</span><span class="n">iterrows</span><span class="p">())</span>

    <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">results</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">r</span><span class="o">.</span><span class="n">get</span><span class="p">()</span>
            <span class="n">pbar</span><span class="o">.</span><span class="n">update</span><span class="p">()</span>
        <span class="k">except</span> <span class="nb">AttributeError</span><span class="p">:</span>
            <span class="n">pbar</span><span class="o">.</span><span class="n">update</span><span class="p">()</span></code></pre></figure><p><code class="highlighter-rouge">scrape_fanfiction.py</code> - scrape all the fanfiction in the universe!!!</p><figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">from</span> <span class="nn">bs4</span> <span class="kn">import</span> <span class="n">BeautifulSoup</span> <span class="k">as</span> <span class="n">bs</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span><span class="p">,</span> <span class="n">trange</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">tables</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">pdb</span>
<span class="kn">import</span> <span class="nn">traceback</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">multiprocessing</span> <span class="k">as</span> <span class="n">mp</span>

<span class="kn">import</span> <span class="nn">argparse</span>


<span class="k">class</span> <span class="nc">Metadata</span><span class="p">(</span><span class="n">tables</span><span class="o">.</span><span class="n">IsDescription</span><span class="p">):</span>
    <span class="s">"""
    Class to describe columns in metadata table
    """</span>
    <span class="n">page_id</span> <span class="o">=</span> <span class="n">tables</span><span class="o">.</span><span class="n">UInt32Col</span><span class="p">()</span>
    <span class="n">page_title</span> <span class="o">=</span> <span class="n">tables</span><span class="o">.</span><span class="n">StringCol</span><span class="p">(</span><span class="mi">512</span><span class="p">)</span>
    <span class="n">title</span> <span class="o">=</span> <span class="n">tables</span><span class="o">.</span><span class="n">StringCol</span><span class="p">(</span><span class="mi">512</span><span class="p">)</span>
    <span class="n">description</span> <span class="o">=</span> <span class="n">tables</span><span class="o">.</span><span class="n">StringCol</span><span class="p">(</span><span class="mi">2048</span><span class="p">)</span>
    <span class="n">rating</span> <span class="o">=</span> <span class="n">tables</span><span class="o">.</span><span class="n">StringCol</span><span class="p">(</span><span class="mi">64</span><span class="p">)</span>
    <span class="n">language</span> <span class="o">=</span> <span class="n">tables</span><span class="o">.</span><span class="n">StringCol</span><span class="p">(</span><span class="mi">128</span><span class="p">)</span>
    <span class="n">chapters</span> <span class="o">=</span> <span class="n">tables</span><span class="o">.</span><span class="n">UInt16Col</span><span class="p">()</span>
    <span class="n">chapter</span> <span class="o">=</span> <span class="n">tables</span><span class="o">.</span><span class="n">UInt16Col</span><span class="p">()</span>
    <span class="n">words</span> <span class="o">=</span> <span class="n">tables</span><span class="o">.</span><span class="n">UInt64Col</span><span class="p">()</span>
    <span class="n">reviews</span> <span class="o">=</span> <span class="n">tables</span><span class="o">.</span><span class="n">UInt32Col</span><span class="p">()</span>
    <span class="n">favs</span> <span class="o">=</span> <span class="n">tables</span><span class="o">.</span><span class="n">UInt32Col</span><span class="p">()</span>
    <span class="n">follows</span> <span class="o">=</span> <span class="n">tables</span><span class="o">.</span><span class="n">UInt32Col</span><span class="p">()</span>
    <span class="n">updated</span> <span class="o">=</span> <span class="n">tables</span><span class="o">.</span><span class="n">StringCol</span><span class="p">(</span><span class="mi">64</span><span class="p">)</span>
    <span class="n">published</span> <span class="o">=</span> <span class="n">tables</span><span class="o">.</span><span class="n">StringCol</span><span class="p">(</span><span class="mi">64</span><span class="p">)</span>
    <span class="n">text_idx</span> <span class="o">=</span> <span class="n">tables</span><span class="o">.</span><span class="n">UInt64Col</span><span class="p">()</span>
    <span class="n">genre</span> <span class="o">=</span> <span class="n">tables</span><span class="o">.</span><span class="n">StringCol</span><span class="p">(</span><span class="mi">256</span><span class="p">)</span>
    <span class="n">characters</span> <span class="o">=</span> <span class="n">tables</span><span class="o">.</span><span class="n">StringCol</span><span class="p">(</span><span class="mi">512</span><span class="p">)</span>
    <span class="n">universe</span> <span class="o">=</span> <span class="n">tables</span><span class="o">.</span><span class="n">StringCol</span><span class="p">(</span><span class="mi">1024</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">scrape_page</span><span class="p">(</span><span class="n">page</span><span class="p">,</span> <span class="n">page_id</span><span class="p">,</span> <span class="n">chapter</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">row</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="s">"""
    Scrape a single page
    """</span>

    <span class="c1"># gather page elements with metadata
</span>    <span class="c1"># small sub element with hyphen-separated descriptors
</span>    <span class="n">profile</span> <span class="o">=</span> <span class="n">page</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="s">"profile_top"</span><span class="p">)</span>
    <span class="n">subheader</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">profile</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="n">class_</span><span class="o">=</span><span class="s">'xgray xcontrast_txt'</span><span class="p">)</span><span class="o">.</span><span class="n">children</span><span class="p">)</span>


    <span class="n">subhead_1</span> <span class="o">=</span> <span class="p">[</span><span class="n">t</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">subheader</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s">'-'</span><span class="p">)]</span>
    <span class="n">subhead_2</span> <span class="o">=</span> <span class="p">[</span><span class="n">t</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">subheader</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s">'-'</span><span class="p">)]</span>

    <span class="c1">#############################
</span>    <span class="c1"># gather metadata -- idiosyncratic selection criteria for the page and its format.
</span>    <span class="c1"># after scraping several thousand pages, there are no obvious failures.
</span>    <span class="n">metadata</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="c1"># these ones are more or less always present, no position correction needed
</span>    <span class="n">metadata</span><span class="p">[</span><span class="s">'page_id'</span><span class="p">]</span> <span class="o">=</span> <span class="n">page_id</span>
    <span class="n">metadata</span><span class="p">[</span><span class="s">"page_title"</span><span class="p">]</span> <span class="o">=</span> <span class="n">page</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s">"title"</span><span class="p">)</span><span class="o">.</span><span class="n">text</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s">'ascii'</span><span class="p">,</span> <span class="n">errors</span><span class="o">=</span><span class="s">"ignore"</span><span class="p">)</span>
    <span class="c1">#metadata["title"] = profile.find("b").text.encode('ascii', errors="ignore")
</span>    <span class="n">metadata</span><span class="p">[</span><span class="s">"description"</span><span class="p">]</span> <span class="o">=</span> <span class="n">profile</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s">'div'</span><span class="p">,</span> <span class="n">recursive</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span><span class="o">.</span><span class="n">text</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s">'ascii'</span><span class="p">,</span> <span class="n">errors</span><span class="o">=</span><span class="s">"ignore"</span><span class="p">)</span>
    <span class="n">metadata</span><span class="p">[</span><span class="s">"rating"</span><span class="p">]</span> <span class="o">=</span> <span class="n">subheader</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">text</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s">'ascii'</span><span class="p">,</span> <span class="n">errors</span><span class="o">=</span><span class="s">"ignore"</span><span class="p">)</span>
    <span class="n">metadata</span><span class="p">[</span><span class="s">"language"</span><span class="p">],</span> <span class="n">metadata</span><span class="p">[</span><span class="s">"genre"</span><span class="p">],</span> <span class="n">metadata</span><span class="p">[</span><span class="s">"characters"</span><span class="p">]</span> <span class="o">=</span> <span class="n">subhead_1</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s">'ascii'</span><span class="p">,</span> <span class="n">errors</span><span class="o">=</span><span class="s">"ignore"</span><span class="p">),</span> <span class="n">subhead_1</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s">'ascii'</span><span class="p">,</span> <span class="n">errors</span><span class="o">=</span><span class="s">"ignore"</span><span class="p">),</span> <span class="n">subhead_1</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s">'ascii'</span><span class="p">,</span> <span class="n">errors</span><span class="o">=</span><span class="s">"ignore"</span><span class="p">)</span>
    <span class="n">metadata</span><span class="p">[</span><span class="s">'chapter'</span><span class="p">]</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">chapter</span><span class="p">)</span>

    <span class="c1"># the following might be present, and so they require special checks
</span>    <span class="k">try</span><span class="p">:</span>
        <span class="n">metadata</span><span class="p">[</span><span class="s">"chapters"</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">c</span><span class="o">.</span><span class="n">strip</span><span class="p">(</span><span class="s">'Chapters: '</span><span class="p">))</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">subhead_1</span> <span class="k">if</span> <span class="n">c</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s">"Chapters:"</span><span class="p">)][</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">except</span><span class="p">:</span>
        <span class="n">metadata</span><span class="p">[</span><span class="s">'chapters'</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>


    <span class="n">metadata</span><span class="p">[</span><span class="s">"words"</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">c</span><span class="o">.</span><span class="n">strip</span><span class="p">(</span><span class="s">'Words: '</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s">','</span><span class="p">,</span> <span class="s">''</span><span class="p">))</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">subhead_1</span> <span class="k">if</span> <span class="n">c</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s">"Words: "</span><span class="p">)][</span><span class="mi">0</span><span class="p">]</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="n">reviews_item</span> <span class="o">=</span> <span class="p">[</span><span class="n">r</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">subheader</span> <span class="k">if</span> <span class="s">'Reviews'</span> <span class="ow">in</span> <span class="n">r</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">reviews_idx</span> <span class="o">=</span> <span class="n">subheader</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">reviews_item</span><span class="p">)</span>
        <span class="n">metadata</span><span class="p">[</span><span class="s">"reviews"</span><span class="p">]</span> <span class="o">=</span> <span class="n">subheader</span><span class="p">[</span><span class="n">reviews_idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">text</span>

    <span class="k">except</span><span class="p">:</span>
        <span class="k">pass</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="n">metadata</span><span class="p">[</span><span class="s">"favs"</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">c</span><span class="o">.</span><span class="n">strip</span><span class="p">(</span><span class="s">"Favs: "</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s">','</span><span class="p">,</span> <span class="s">''</span><span class="p">))</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">subhead_2</span> <span class="k">if</span> <span class="n">c</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s">'Favs'</span><span class="p">)][</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">except</span><span class="p">:</span>
        <span class="n">metadata</span><span class="p">[</span><span class="s">'favs'</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="n">metadata</span><span class="p">[</span><span class="s">"follows"</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">c</span><span class="o">.</span><span class="n">strip</span><span class="p">(</span><span class="s">"Follows: "</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s">','</span><span class="p">,</span> <span class="s">''</span><span class="p">))</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">subhead_2</span> <span class="k">if</span> <span class="n">c</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s">'Follows'</span><span class="p">)][</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">except</span><span class="p">:</span>
        <span class="n">metadata</span><span class="p">[</span><span class="s">'follows'</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="n">updated_item</span> <span class="o">=</span> <span class="p">[</span><span class="n">r</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">subheader</span> <span class="k">if</span> <span class="s">'Published'</span> <span class="ow">in</span> <span class="n">r</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">updated_idx</span> <span class="o">=</span> <span class="n">subheader</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">updated_item</span><span class="p">)</span>
        <span class="n">metadata</span><span class="p">[</span><span class="s">"updated"</span><span class="p">]</span> <span class="o">=</span> <span class="n">subheader</span><span class="p">[</span><span class="n">updated_idx</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">text</span>
    <span class="k">except</span><span class="p">:</span>
        <span class="k">pass</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="n">published_item</span> <span class="o">=</span> <span class="p">[</span><span class="n">r</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">subheader</span> <span class="k">if</span> <span class="s">'Published'</span> <span class="ow">in</span> <span class="n">r</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">published_idx</span> <span class="o">=</span> <span class="n">subheader</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">published_item</span><span class="p">)</span>
        <span class="n">metadata</span><span class="p">[</span><span class="s">"published"</span><span class="p">]</span> <span class="o">=</span> <span class="n">subheader</span><span class="p">[</span><span class="n">published_idx</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">text</span>
    <span class="k">except</span><span class="p">:</span>
        <span class="k">pass</span>

    <span class="c1">#metadata["text_idx"] = texts.nrows
</span>
    <span class="c1"># add data from the row
</span>    <span class="n">metadata</span><span class="p">[</span><span class="s">'universe'</span><span class="p">]</span> <span class="o">=</span> <span class="n">row</span><span class="o">.</span><span class="n">universe</span>
    <span class="n">metadata</span><span class="p">[</span><span class="s">'title'</span><span class="p">]</span> <span class="o">=</span> <span class="n">row</span><span class="p">[</span><span class="s">'name'</span><span class="p">]</span>


    <span class="n">text</span> <span class="o">=</span> <span class="n">page</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="s">"storytext"</span><span class="p">)</span><span class="o">.</span><span class="n">text</span>

    <span class="k">return</span> <span class="n">metadata</span><span class="p">,</span> <span class="n">text</span>

<span class="k">def</span> <span class="nf">scrape_story</span><span class="p">(</span><span class="n">row</span><span class="p">):</span>
    <span class="s">"""
    Scrape all pages of a story, including chapters.
    """</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">i</span><span class="p">,</span> <span class="n">row</span> <span class="o">=</span> <span class="n">row</span>

        <span class="k">global</span> <span class="n">do_multi</span>
        <span class="k">if</span> <span class="n">do_multi</span><span class="p">:</span>
            <span class="n">current</span> <span class="o">=</span> <span class="n">mp</span><span class="o">.</span><span class="n">current_process</span><span class="p">()</span>
            <span class="n">tqdm_position</span> <span class="o">=</span> <span class="n">current</span><span class="o">.</span><span class="n">_identity</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">+</span><span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">tqdm_position</span> <span class="o">=</span> <span class="mi">1</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="n">url_id</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">row</span><span class="o">.</span><span class="nb">id</span><span class="p">)</span><span class="o">.</span><span class="n">zfill</span><span class="p">(</span><span class="mi">7</span><span class="p">)</span>
        <span class="k">except</span><span class="p">:</span>
            <span class="n">url_id</span> <span class="o">=</span> <span class="n">row</span><span class="o">.</span><span class="nb">id</span>

        <span class="n">page_url</span> <span class="o">=</span> <span class="s">"https://www.fanfiction.net/s/{}/"</span><span class="o">.</span><span class="nb">format</span><span class="p">(</span><span class="n">url_id</span><span class="p">)</span>
        <span class="n">page</span> <span class="o">=</span> <span class="n">bs</span><span class="p">(</span><span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">page_url</span><span class="p">)</span><span class="o">.</span><span class="n">content</span><span class="p">,</span> <span class="s">'lxml'</span><span class="p">)</span>

        <span class="c1"># determine whether a story is had here, if not skip this page.
</span>        <span class="k">try</span><span class="p">:</span>
            <span class="n">warning</span> <span class="o">=</span> <span class="n">page</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="n">class_</span><span class="o">=</span><span class="s">"gui_warning"</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">warning</span><span class="o">.</span><span class="n">text</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s">"Story Not Found"</span><span class="p">):</span>
                <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">'fanfic_log.txt'</span><span class="p">,</span> <span class="s">'a'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
                    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s">"Story not found, id: {}"</span><span class="o">.</span><span class="nb">format</span><span class="p">(</span><span class="n">row</span><span class="o">.</span><span class="nb">id</span><span class="p">))</span>
                <span class="k">return</span> <span class="p">[</span><span class="bp">False</span><span class="p">],</span> <span class="p">[</span><span class="bp">False</span><span class="p">]</span>
        <span class="k">except</span> <span class="nb">AttributeError</span><span class="p">:</span>
            <span class="c1"># didn't find warning, so Nonetype has no 'text'
</span>            <span class="k">pass</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="c1"># new error - weird blank page
</span>            <span class="n">warning</span> <span class="o">=</span> <span class="n">page</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="n">class_</span><span class="o">=</span><span class="s">"gui_normal"</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">warning</span><span class="o">.</span><span class="n">text</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s">"Please check to see you are not using an outdated url."</span><span class="p">):</span>
                <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">'fanfic_log.txt'</span><span class="p">,</span> <span class="s">'a'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
                    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s">"Outdated URL, id: {}"</span><span class="o">.</span><span class="nb">format</span><span class="p">(</span><span class="n">row</span><span class="o">.</span><span class="nb">id</span><span class="p">))</span>
                <span class="k">return</span> <span class="p">[</span><span class="bp">False</span><span class="p">],</span> <span class="p">[</span><span class="bp">False</span><span class="p">]</span>
        <span class="k">except</span> <span class="nb">AttributeError</span><span class="p">:</span>
            <span class="k">pass</span>

        <span class="c1"># figure out if story has chapters
</span>        <span class="n">chapter_select</span> <span class="o">=</span> <span class="n">page</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="s">"chap_select"</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">chapter_select</span><span class="p">:</span>
            <span class="n">has_chapters</span> <span class="o">=</span> <span class="bp">True</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">has_chapters</span> <span class="o">=</span> <span class="bp">False</span>

        <span class="c1"># scrape the first page and save data
</span>
        <span class="n">metadata</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">text</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="n">metadata_1</span><span class="p">,</span> <span class="n">text_1</span> <span class="o">=</span> <span class="n">scrape_page</span><span class="p">(</span><span class="n">page</span><span class="p">,</span> <span class="n">page_id</span><span class="o">=</span><span class="n">url_id</span><span class="p">,</span> <span class="n">row</span><span class="o">=</span><span class="n">row</span><span class="p">)</span>
        <span class="n">metadata</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">metadata_1</span><span class="p">)</span>
        <span class="n">text</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">text_1</span><span class="p">)</span>

        <span class="c1"># if the text has chapters, iterate.
</span>        <span class="k">if</span> <span class="n">has_chapters</span><span class="p">:</span>
            <span class="n">n_chapters</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">chapter_select</span><span class="o">.</span><span class="n">children</span><span class="p">))</span>
            <span class="n">pbar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">position</span><span class="o">=</span><span class="n">tqdm_position</span><span class="p">,</span> <span class="n">total</span><span class="o">=</span><span class="n">n_chapters</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">chapter_number</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_chapters</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
                <span class="n">chap_url</span> <span class="o">=</span> <span class="n">page_url</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">chapter_number</span><span class="p">)</span> <span class="o">+</span> <span class="s">"/"</span>
                <span class="n">page</span> <span class="o">=</span> <span class="n">bs</span><span class="p">(</span><span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">chap_url</span><span class="p">)</span><span class="o">.</span><span class="n">content</span><span class="p">,</span> <span class="s">'lxml'</span><span class="p">)</span>
                <span class="n">metadata_chap</span><span class="p">,</span> <span class="n">text_chap</span> <span class="o">=</span> <span class="n">scrape_page</span><span class="p">(</span><span class="n">page</span><span class="p">,</span> <span class="n">page_id</span><span class="o">=</span><span class="n">url_id</span><span class="p">,</span> <span class="n">chapter</span><span class="o">=</span><span class="n">chapter_number</span><span class="p">,</span> <span class="n">row</span><span class="o">=</span><span class="n">row</span><span class="p">)</span>
                <span class="n">metadata</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">metadata_chap</span><span class="p">)</span>
                <span class="n">text</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">text_chap</span><span class="p">)</span>
                <span class="n">pbar</span><span class="o">.</span><span class="n">update</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">metadata</span><span class="p">,</span> <span class="n">text</span>

    <span class="k">except</span> <span class="nb">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>


        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">'fanfic_log.txt'</span><span class="p">,</span> <span class="s">'a'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">row</span><span class="p">))</span>
            <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">))</span>
            <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">traceback</span><span class="o">.</span><span class="n">format_exc</span><span class="p">())</span>

        <span class="k">return</span> <span class="p">[</span><span class="bp">False</span><span class="p">],</span> <span class="p">[</span><span class="bp">False</span><span class="p">]</span>



<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">"__main__"</span><span class="p">:</span>
    <span class="n">parser</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">()</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s">'--list'</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s">'index file'</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s">'--output'</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s">'output file path'</span><span class="p">)</span>
    <span class="n">args</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_args</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="nb">list</span><span class="p">:</span>
        <span class="n">list_path</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="nb">list</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">list_path</span> <span class="o">=</span> <span class="s">'story_idx.pck.gz'</span>

    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">output</span><span class="p">:</span>
        <span class="n">output_path</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">output</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">output_path</span> <span class="o">=</span> <span class="s">'fanfiction.h5'</span>

    <span class="k">print</span><span class="p">(</span><span class="s">'</span><span class="se">\n</span><span class="s">reading story index'</span><span class="p">)</span>
    <span class="n">stories</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_pickle</span><span class="p">(</span><span class="n">list_path</span><span class="p">,</span> <span class="n">compression</span><span class="o">=</span><span class="s">'gzip'</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'</span><span class="se">\n</span><span class="s">story index read, scraping {} stories'</span><span class="o">.</span><span class="nb">format</span><span class="p">(</span><span class="n">stories</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>

    <span class="c1"># open hdf5 file to write to
</span>
    <span class="nb">filter</span> <span class="o">=</span> <span class="n">tables</span><span class="o">.</span><span class="n">Filters</span><span class="p">(</span><span class="n">complib</span><span class="o">=</span><span class="s">'lzo'</span><span class="p">,</span> <span class="n">complevel</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
    <span class="n">h5f</span> <span class="o">=</span> <span class="n">tables</span><span class="o">.</span><span class="n">open_file</span><span class="p">(</span><span class="n">output_path</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s">"a"</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s">"fanfiction.net"</span><span class="p">,</span> <span class="n">filters</span><span class="o">=</span><span class="nb">filter</span><span class="p">)</span>

    <span class="c1"># if metadata table doesn't exist, make it, otherwise get the reference to it
</span>    <span class="k">try</span><span class="p">:</span>
        <span class="n">tab</span> <span class="o">=</span> <span class="n">h5f</span><span class="o">.</span><span class="n">create_table</span><span class="p">(</span><span class="s">'/'</span><span class="p">,</span> <span class="s">"metadata"</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="n">Metadata</span><span class="p">,</span> <span class="n">filters</span><span class="o">=</span><span class="nb">filter</span><span class="p">)</span>
    <span class="k">except</span> <span class="n">tables</span><span class="o">.</span><span class="n">exceptions</span><span class="o">.</span><span class="n">NodeError</span><span class="p">:</span>
        <span class="n">tab</span> <span class="o">=</span> <span class="n">h5f</span><span class="o">.</span><span class="n">get_node</span><span class="p">(</span><span class="s">'/'</span><span class="p">,</span> <span class="s">"metadata"</span><span class="p">)</span>

    <span class="c1"># same with texts, though we'll use a variable-length unicode
</span>    <span class="c1"># format, which can only be a single column array.
</span>    <span class="k">try</span><span class="p">:</span>
        <span class="n">texts</span> <span class="o">=</span> <span class="n">h5f</span><span class="o">.</span><span class="n">create_vlarray</span><span class="p">(</span><span class="n">h5f</span><span class="o">.</span><span class="n">root</span><span class="p">,</span> <span class="s">'texts'</span><span class="p">,</span>
                                   <span class="n">tables</span><span class="o">.</span><span class="n">VLUnicodeAtom</span><span class="p">(),</span> <span class="n">filters</span><span class="o">=</span><span class="nb">filter</span><span class="p">)</span>
    <span class="k">except</span> <span class="n">tables</span><span class="o">.</span><span class="n">exceptions</span><span class="o">.</span><span class="n">NodeError</span><span class="p">:</span>
        <span class="n">texts</span> <span class="o">=</span> <span class="n">h5f</span><span class="o">.</span><span class="n">get_node</span><span class="p">(</span><span class="s">'/'</span><span class="p">,</span> <span class="s">'texts'</span><span class="p">)</span>

    <span class="c1"># remove stories that have already been scraped
</span>    <span class="k">print</span><span class="p">(</span><span class="s">'loading ids of stories that have already been scraped...'</span><span class="p">)</span>
    <span class="c1">#scraped_ids = tab.col('page_id')
</span>    <span class="n">all_scraped_ids</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">scraped_ids</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
    <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">tab</span><span class="p">,</span> <span class="n">total</span><span class="o">=</span><span class="n">tab</span><span class="o">.</span><span class="n">nrows</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">i</span><span class="o">&gt;</span><span class="mi">0</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">1000000</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">all_scraped_ids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">scraped_ids</span><span class="p">)</span>
            <span class="n">scraped_ids</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
        <span class="n">scraped_ids</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="s">'page_id'</span><span class="p">])</span>
        <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="n">all_scraped_ids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">scraped_ids</span><span class="p">)</span>
    <span class="n">scraped_ids</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span><span class="o">.</span><span class="n">union</span><span class="p">(</span><span class="o">*</span><span class="n">all_scraped_ids</span><span class="p">)</span>

    <span class="k">print</span><span class="p">(</span><span class="s">'looking for stories that have already been scraped (this might take a minute)...'</span><span class="p">)</span>

    <span class="n">already_got</span> <span class="o">=</span> <span class="n">stories</span><span class="p">[</span><span class="s">'id'</span><span class="p">]</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">scraped_ids</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'</span><span class="se">\n</span><span class="s">Already have {} stories, skipping those'</span><span class="o">.</span><span class="nb">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">already_got</span><span class="p">)))</span>

    <span class="n">stories</span> <span class="o">=</span> <span class="n">stories</span><span class="p">[</span><span class="o">~</span><span class="n">already_got</span><span class="p">]</span>


    <span class="c1"># the row class allows us to write iteratively to the pytable
</span>    <span class="n">tab_row</span> <span class="o">=</span> <span class="n">tab</span><span class="o">.</span><span class="n">row</span>

    <span class="c1"># figure out where we start &amp; end. each page number is a 7-8 digit int.
</span>    <span class="k">global</span> <span class="n">do_multi</span>
    <span class="n">do_multi</span> <span class="o">=</span> <span class="bp">True</span>

    <span class="n">pbar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">total</span><span class="o">=</span><span class="n">stories</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">position</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">do_multi</span><span class="p">:</span>

        <span class="k">for</span> <span class="n">arow</span> <span class="ow">in</span> <span class="n">stories</span><span class="o">.</span><span class="n">iterrows</span><span class="p">():</span>
            <span class="n">metadata</span><span class="p">,</span> <span class="n">text</span> <span class="o">=</span> <span class="n">scrape_story</span><span class="p">(</span><span class="n">arow</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">meta</span><span class="p">,</span> <span class="n">tex</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">metadata</span><span class="p">,</span> <span class="n">text</span><span class="p">):</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">meta</span><span class="p">:</span>
                    <span class="c1">#print(meta, tex)
</span>                    <span class="k">continue</span>
                <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">meta</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                        <span class="n">v</span> <span class="o">=</span> <span class="n">v</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s">'ascii'</span><span class="p">,</span> <span class="n">errors</span><span class="o">=</span><span class="s">'ignore'</span><span class="p">)</span>
                    <span class="k">try</span><span class="p">:</span>
                        <span class="n">tab_row</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span>
                    <span class="k">except</span> <span class="nb">TypeError</span><span class="p">:</span>
                        <span class="c1"># could be a number with a comma..
</span>                        <span class="n">v</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">v</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">b</span><span class="s">','</span><span class="p">,</span> <span class="n">b</span><span class="s">''</span><span class="p">))</span>
                        <span class="n">tab_row</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span>

                <span class="n">tab_row</span><span class="o">.</span><span class="n">append</span><span class="p">()</span>
                <span class="n">texts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">tex</span><span class="p">))</span>

            <span class="n">tab</span><span class="o">.</span><span class="n">flush</span><span class="p">()</span>
            <span class="n">texts</span><span class="o">.</span><span class="n">flush</span><span class="p">()</span>
            <span class="n">pbar</span><span class="o">.</span><span class="n">update</span><span class="p">()</span>


    <span class="k">else</span><span class="p">:</span>



        <span class="c1"># create pool of workers
</span>        <span class="n">pool</span> <span class="o">=</span> <span class="n">mp</span><span class="o">.</span><span class="n">Pool</span><span class="p">(</span><span class="mi">24</span><span class="p">)</span>



        <span class="n">results</span> <span class="o">=</span> <span class="n">pool</span><span class="o">.</span><span class="n">imap_unordered</span><span class="p">(</span><span class="n">scrape_story</span><span class="p">,</span> <span class="n">stories</span><span class="o">.</span><span class="n">iterrows</span><span class="p">())</span>

        <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">results</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="c1">#try:
</span>                <span class="c1">#pdb.set_trace()
</span>                <span class="n">metadata</span><span class="p">,</span> <span class="n">text</span> <span class="o">=</span> <span class="n">r</span>
                <span class="k">for</span> <span class="n">meta</span><span class="p">,</span> <span class="n">tex</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">metadata</span><span class="p">,</span> <span class="n">text</span><span class="p">):</span>
                    <span class="k">if</span> <span class="p">(</span><span class="ow">not</span> <span class="n">meta</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="ow">not</span> <span class="n">tex</span><span class="p">):</span>
                        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">'fanfic_log.txt'</span><span class="p">,</span> <span class="s">'a'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
                            <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="s">'skipping'</span><span class="p">))</span>
                        <span class="k">continue</span>
                    <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">meta</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                            <span class="n">v</span> <span class="o">=</span> <span class="n">v</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s">'ascii'</span><span class="p">,</span> <span class="n">errors</span><span class="o">=</span><span class="s">'ignore'</span><span class="p">)</span>
                        <span class="k">try</span><span class="p">:</span>
                            <span class="n">tab_row</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span>
                        <span class="k">except</span> <span class="nb">TypeError</span><span class="p">:</span>
                            <span class="c1"># could be a number with a comma..
</span>                            <span class="n">v</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">v</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">b</span><span class="s">','</span><span class="p">,</span> <span class="n">b</span><span class="s">''</span><span class="p">))</span>
                            <span class="n">tab_row</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span>
                    <span class="n">tab_row</span><span class="o">.</span><span class="n">append</span><span class="p">()</span>
                    <span class="n">texts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">tex</span><span class="p">))</span>

                <span class="n">tab</span><span class="o">.</span><span class="n">flush</span><span class="p">()</span>
                <span class="n">texts</span><span class="o">.</span><span class="n">flush</span><span class="p">()</span>
                <span class="n">pbar</span><span class="o">.</span><span class="n">update</span><span class="p">()</span>

            <span class="k">except</span> <span class="nb">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">'fanfic_log.txt'</span><span class="p">,</span> <span class="s">'a'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
                    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">))</span>
                    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">traceback</span><span class="o">.</span><span class="n">format_exc</span><span class="p">())</span>


    <span class="n">h5f</span><span class="o">.</span><span class="n">flush</span><span class="p">()</span>
    <span class="n">h5f</span><span class="o">.</span><span class="n">close</span><span class="p">()</span></code></pre></figure><p>And the smut itself:</p><script src="https://cdnjs.cloudflare.com/ajax/libs/pdfobject/2.1.1/pdfobject.min.js" integrity="sha256-rYPX3dXq8Nh532EvCS2foeyTgmzbcC8u+nCk/rEtKXA=" crossorigin="anonymous"></script><div id="autopotterotica" style="width:100%;min-height:50vh;"></div><script> PDFObject.embed( "/blog/assets/hosted/autopotterotica_excerpts.pdf", "#autopotterotica"); </script><h2 id="schillbot-20191003">schillbot (2019.10.03)</h2><p>To get under the paper-thin skin of our university’s president while he was trying to balance the budget by taking medicine from graduate workers who make poverty wages, I made a twitter bot to mock him. The bot posted either a real quote or a neural-net generated quote and asked people to vote which one they thought it was.</p><p>I scraped all his often off-the-rails emails and writing from his website and trained a transformer model. This was before the proliferation of all these newfangled GPT-2 fine-tuned models, so it’s a little rough, but these are some of my favorites:</p><p>Look! even the wonderful Janelle Shane helped out!</p><blockquote class="twitter-tweet"><p lang="en" dir="ltr">neural net as activism: Univ of Oregon grad students, negotiating to save their health care benefits, raise awareness by training a bot on their university president&#39;s writing<br /><br />via <a href="https://twitter.com/GTFF_3544?ref_src=twsrc%5Etfw">@GTFF_3544</a> <a href="https://t.co/4Jl1nx5fTo">https://t.co/4Jl1nx5fTo</a></p>&mdash; Janelle Shane (@JanelleCShane) <a href="https://twitter.com/JanelleCShane/status/1180271783993200640?ref_src=twsrc%5Etfw">October 5, 2019</a></blockquote><script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script><blockquote class="twitter-tweet"><p lang="en" dir="ltr">&quot;first we must provide services and I am committed to extraordinarily egregious cost-reduction goals&quot; <a href="https://t.co/WnfYOHRvLG">https://t.co/WnfYOHRvLG</a></p>&mdash; schillbot_3000 (@schillbot3000) <a href="https://twitter.com/schillbot3000/status/1130263478206210048?ref_src=twsrc%5Etfw">May 20, 2019</a></blockquote><script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script><blockquote class="twitter-tweet"><p lang="en" dir="ltr">&quot;i know some of you read this, roll your eyes, but any of you who know me know i am a little boy.&quot; <a href="https://t.co/WnfYOHRvLG">https://t.co/WnfYOHRvLG</a></p>&mdash; schillbot_3000 (@schillbot3000) <a href="https://twitter.com/schillbot3000/status/1186729816935956480?ref_src=twsrc%5Etfw">October 22, 2019</a></blockquote><script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script><blockquote class="twitter-tweet"><p lang="en" dir="ltr">&quot;Full combat provost.&quot;</p>&mdash; schillbot_3000 (@schillbot3000) <a href="https://twitter.com/schillbot3000/status/1132499163252314112?ref_src=twsrc%5Etfw">May 26, 2019</a></blockquote><script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script><blockquote class="twitter-tweet"><p lang="en" dir="ltr">&quot;i am committed to doing everything in my power to cushion the impact of this great university&quot; <a href="https://t.co/WnfYOHRvLG">https://t.co/WnfYOHRvLG</a></p>&mdash; schillbot_3000 (@schillbot3000) <a href="https://twitter.com/schillbot3000/status/1181295022538280960?ref_src=twsrc%5Etfw">October 7, 2019</a></blockquote><script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script><blockquote class="twitter-tweet"><p lang="en" dir="ltr">&quot;please join me in this effort to address these issues as i apologize.&quot; <a href="https://t.co/WnfYOHRvLG">https://t.co/WnfYOHRvLG</a></p>&mdash; schillbot_3000 (@schillbot3000) <a href="https://twitter.com/schillbot3000/status/1181706316303101952?ref_src=twsrc%5Etfw">October 8, 2019</a></blockquote><script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script><blockquote class="twitter-tweet"><p lang="en" dir="ltr">&quot;over the past several months, we have experienced enormous churn in our boys by opening the doors of establish world-class research&quot; <a href="https://t.co/WnfYOHRvLG">https://t.co/WnfYOHRvLG</a></p>&mdash; schillbot_3000 (@schillbot3000) <a href="https://twitter.com/schillbot3000/status/1187033715743981568?ref_src=twsrc%5Etfw">October 23, 2019</a></blockquote><script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script><blockquote class="twitter-tweet"><p lang="en" dir="ltr">&quot;i am announcing these decisions now because i am not know the victim or the pain they will be doing&quot; <a href="https://t.co/WnfYOHRvLG">https://t.co/WnfYOHRvLG</a></p>&mdash; schillbot_3000 (@schillbot3000) <a href="https://twitter.com/schillbot3000/status/1132549248413650946?ref_src=twsrc%5Etfw">May 26, 2019</a></blockquote><script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script><blockquote class="twitter-tweet"><p lang="en" dir="ltr">&quot;i can go on to become one of the reasons why the university athletic fields will be in command of our state.&quot; <a href="https://t.co/WnfYOHRvLG">https://t.co/WnfYOHRvLG</a></p>&mdash; schillbot_3000 (@schillbot3000) <a href="https://twitter.com/schillbot3000/status/1180510220260274176?ref_src=twsrc%5Etfw">October 5, 2019</a></blockquote><script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script><blockquote class="twitter-tweet"><p lang="en" dir="ltr">&quot;during the summer months of that year, president michael schill shared his thoughts on the university&#39;s priorities: hard rock, my website&quot; <a href="https://t.co/WnfYOHRvLG">https://t.co/WnfYOHRvLG</a></p>&mdash; schillbot_3000 (@schillbot3000) <a href="https://twitter.com/schillbot3000/status/1183827424758288385?ref_src=twsrc%5Etfw">October 14, 2019</a></blockquote><script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script><h2 id="red-eyes-on-statues-20190803">red eyes on statues (2019.08.03)</h2><p>A good friend sent me this:</p><p><img src="/blog/assets/images/artvol2/redeyes_inspo.png" alt="redeyes inspo" /></p><p>So I copied it.</p><p>First I made some led-bombs by rigging them up to a 9V battery w/ a photodiode that turns the light off during the day to make them last longer.</p><video controls="" preload="none" style="max-height: 70vh;"> <source src="/blog/assets/images/artvol2/redeyes_prototype.mp4" type="video/mp4" /> </video><p>Then I attached them to a few statues around UO. I didn’t really photograph or catch much video of this because I was basically in a fugue state from being deliriously heartbroken and it was maybe a little bit of vandalism.</p><video controls="" preload="none"> <source src="/blog/assets/images/artvol2/redeyes_install.mp4" type="video/mp4" /> </video><h1 id="design">Design</h1><h2 id="autopilot-20191017">Autopilot (2019.10.17)</h2><p>I released some <a href="https://auto-pi-lot.com">software</a> and wrote a <a href="https://www.biorxiv.org/content/10.1101/807693v1">paper</a> to describe it, and I spent a lot of time to make a beautiful document. Typography is another art I am working to get better at, and I don’t really want to clutter up this post with a million page excerpts, but I am very proud of the way the figures are integrated with the text.</p><p>I will include the documentation logo that I like a lot though.</p><video controls="" preload="none"> <source src="/blog/assets/images/artvol2/autopilot_logo_loop.mp4" type="video/mp4" /> </video><h2 id="union-propaganda">Union Propaganda</h2><p>I don’t contribute enough to my union, but the one thing that I do contribute is a bit of design. These were all made during our most recent round of bargaining, which revealed what an amoral disaster of an institution the University of Oregon is.</p><h3 class="no_toc" id="uohellnocom">uohellno.com</h3><p>This was the website linked to by the schillbot. It works pretty badly on mobile (it was my first d3 scroller), so it will probably work even worse in this little iframe. may just want to visit <a href="https://uohellno.com">uohellno.com</a></p><p><a data-fancybox="" data-type="iframe" href="https://uohellno.com" class="iframe-preview">Open demo</a></p><h3 class="no_toc" id="salaries">Salaries</h3><p>Data available here: <a href="https://github.com/sneakers-the-rat/uoregon_salary_data">https://github.com/sneakers-the-rat/uoregon_salary_data</a></p><p><img src="/blog/assets/images/artvol2/gtff_salary.png" alt="UO exec salary nonsense" /></p><h3 class="no_toc" id="uoregons-healthcare-swindle">UOregon’s Healthcare Swindle</h3><p><img src="/blog/assets/images/artvol2/gtff_longterm.png" alt="longterm insurance costs" /></p><h1 id="stupid-bullshit-projects">stupid bullshit projects</h1><p>And finally, a bunch of other assorted scraps and pieces presented more or less without comment.</p><p><img src="/blog/assets/images/artvol2/the_great_bumblefuck.png" alt="talking 2 people" /></p><p>My department does “bullshit research talks” at our retreats, where someone makes a ridiculous presentation and someone else has to present it. Having someone I look up to very much present this neural-net face swap was one of my finest moments.</p><p><img src="/blog/assets/images/artvol2/matt_yashar_slide.png" alt="matt yashar slide" /></p><p><img src="/blog/assets/images/artvol2/matt_yashar_presentation.jpg" alt="matt yashar morph presentation" /></p><p><img src="/blog/assets/images/artvol2/dolphen.jpg" alt="dolphen" /></p><p>someone I love very much loves Selena very much, so this was for them.</p><p><img src="/blog/assets/images/artvol2/selena_centaur.png" alt="selena centaur" /></p><p><img src="/blog/assets/images/artvol2/MRPEANUT.png" alt="mr peanut" /></p><p><img src="/blog/assets/images/artvol2/heavy_breathing.jpg" alt="heavy breathing" /></p><p><img src="/blog/assets/images/artvol2/eurovision_heatmap.png" alt="eurovision heatmap" /></p><video controls="" preload="none" style="max-height: 70vh;"> <source src="/blog/assets/images/artvol2/goyles.mp4" type="video/mp4" /> </video><p>This was a gift I made for a dear dear friend that I unfortunately didn’t ever take a photo of the finished version. These panels stack together and have a few very fond memories in them. In this image: She is the sun, and i am the moon. one of the first memories I have with her is drunkenly fucking up someone else’s car radio (and it also fit iwth the scene), and nowadays I don’t see her much in part because she is busy all over the world &lt;3.</p><p><img src="/blog/assets/images/artvol2/jackie_gift.jpg" alt="jackie's gift" /></p><p><img src="/blog/assets/images/artvol2/pitchforkyrnose7.png" alt="pitchfork yr nose" /></p><p>Another dear dear friend got married last summer, and her maid of honor asked us to bring a photo of us together to their wedding. Shitty photoshop, but shitty photoshops are sorta one of the things we have a deep and shared love for.</p><p><img src="/blog/assets/images/artvol2/kris_faceswapped.png" alt="matt yashar morph presentation" /></p></div><div class="toc-container section-padding hidden-sm"><div class="sticky-top post-toc markdown-class"><ul class="section-nav"><li class="toc-entry toc-h1"><a href="#with-music">With Music</a><ul><li class="toc-entry toc-h2"><a href="#murmuration-20200210">Murmuration (2020.02.10)</a></li><li class="toc-entry toc-h2"><a href="#thao--the-get-down-stay-down---a-man-alive-20200127">Thao &amp; The Get Down Stay Down - A Man Alive (2020.01.27)</a></li><li class="toc-entry toc-h2"><a href="#nick-hakim---miss-chew-20191102">Nick Hakim - Miss Chew (2019.11.02)</a></li><li class="toc-entry toc-h2"><a href="#tirzah---affection-20191022">Tirzah - Affection (2019.10.22)</a></li></ul></li><li class="toc-entry toc-h1"><a href="#webzones">Webzones</a><ul><li class="toc-entry toc-h2"><a href="#perlin-particles-20200119">Perlin Particles (2020.01.19)</a></li><li class="toc-entry toc-h2"><a href="#how-to-never-get-hired-for-any-job-pt-2-20191219">how to never get hired for any job pt 2. (2019.12.19)</a></li><li class="toc-entry toc-h2"><a href="#speeding-atlas-20191115">Speeding Atlas (2019.11.15)</a></li></ul></li><li class="toc-entry toc-h1"><a href="#alternative-media">~alternative media~</a><ul><li class="toc-entry toc-h2"><a href="#instagram-filters-20200119">instagram filters (2020.01.19)</a></li><li class="toc-entry toc-h2"><a href="#autopotterotica-20200101">Autopotterotica (2020.01.01)</a></li><li class="toc-entry toc-h2"><a href="#schillbot-20191003">schillbot (2019.10.03)</a></li><li class="toc-entry toc-h2"><a href="#red-eyes-on-statues-20190803">red eyes on statues (2019.08.03)</a></li></ul></li><li class="toc-entry toc-h1"><a href="#design">Design</a><ul><li class="toc-entry toc-h2"><a href="#autopilot-20191017">Autopilot (2019.10.17)</a></li><li class="toc-entry toc-h2"><a href="#union-propaganda">Union Propaganda</a></li></ul></li><li class="toc-entry toc-h1"><a href="#stupid-bullshit-projects">stupid bullshit projects</a></li></ul></div></div></div><div class="row"><ul class="post__social"><li><a href="https://www.facebook.com/sharer/sharer.php?u=https://jon-e.net/blog/2020/03/29/Past-Art-Vol-2/" target="_blank"><i class="fa fa-facebook"></i></a></li><li><a href="https://twitter.com/intent/tweet?&text=Past Art Vol 2: About a Year of It+https://jon-e.net/blog/2020/03/29/Past-Art-Vol-2/+by+Jonny Saunders" target="_blank"><i class="fa fa-twitter"></i></a></li><li><a href="https://plus.google.com/share?url=https://jon-e.net/blog/2020/03/29/Past-Art-Vol-2/" target="_blank"><i class="fa fa-google-plus"></i></a></li><li><a href="https://www.linkedin.com/shareArticle?mini=true&source=Past Art Vol 2: About a Year of It&summary=Collecting the scraps from about a year of wasting my time&url=https://jon-e.net/blog/2020/03/29/Past-Art-Vol-2/" target="_blank"><i class="fa fa-linkedin"></i></a></li><li><a href="https://www.stumbleupon.com/badge/?url=https://jon-e.net/blog/2020/03/29/Past-Art-Vol-2/" target="_blank"><i class="fa fa-stumbleupon"></i></a></li><li><a href="https://www.reddit.com/submit?url=https://jon-e.net/blog/2020/03/29/Past-Art-Vol-2/" target="_blank"><i class="fa fa-reddit-alien"></i></a></li><li><a href="https://www.tumblr.com/share/link?url=https://jon-e.net/blog/2020/03/29/Past-Art-Vol-2/" target="_blank"><i class="fa fa-tumblr"></i></a></li><li><a href="https://www.pinterest.com/pin/create/link/?description=Collecting the scraps from about a year of wasting my time&media=https://jon-e.net/blog/blog/assets/images/artvol2/endless_love.png&url=https://jon-e.net/blog/2020/03/29/Past-Art-Vol-2/" target="_blank"><i class="fa fa-pinterest"></i></a></li></ul></div><h2 id="schillbot-20191003">schillbot (2019.10.03)</h2><p>To get under the paper-thin skin of our university’s president while he was trying to balance the budget by taking medicine from graduate workers who make poverty wages, I made a twitter bot to mock him. The bot posted either a real quote or a neural-net generated quote and asked people to vote which one they thought it was.</p><p>I scraped all his often off-the-rails emails and writing from his website and trained a transformer model. This was before the proliferation of all these newfangled GPT-2 fine-tuned models, so it’s a little rough, but these are some of my favorites:</p><p>Look! even the wonderful Janelle Shane helped out!</p><blockquote class="twitter-tweet"><p lang="en" dir="ltr">neural net as activism: Univ of Oregon grad students, negotiating to save their health care benefits, raise awareness by training a bot on their university president&#39;s writing<br /><br />via <a href="https://twitter.com/GTFF_3544?ref_src=twsrc%5Etfw">@GTFF_3544</a> <a href="https://t.co/4Jl1nx5fTo">https://t.co/4Jl1nx5fTo</a></p>&mdash; Janelle Shane (@JanelleCShane) <a href="https://twitter.com/JanelleCShane/status/1180271783993200640?ref_src=twsrc%5Etfw">October 5, 2019</a></blockquote><script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script><blockquote class="twitter-tweet"><p lang="en" dir="ltr">&quot;first we must provide services and I am committed to extraordinarily egregious cost-reduction goals&quot; <a href="https://t.co/WnfYOHRvLG">https://t.co/WnfYOHRvLG</a></p>&mdash; schillbot_3000 (@schillbot3000) <a href="https://twitter.com/schillbot3000/status/1130263478206210048?ref_src=twsrc%5Etfw">May 20, 2019</a></blockquote><script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script><blockquote class="twitter-tweet"><p lang="en" dir="ltr">&quot;i know some of you read this, roll your eyes, but any of you who know me know i am a little boy.&quot; <a href="https://t.co/WnfYOHRvLG">https://t.co/WnfYOHRvLG</a></p>&mdash; schillbot_3000 (@schillbot3000) <a href="https://twitter.com/schillbot3000/status/1186729816935956480?ref_src=twsrc%5Etfw">October 22, 2019</a></blockquote><script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script><blockquote class="twitter-tweet"><p lang="en" dir="ltr">&quot;Full combat provost.&quot;</p>&mdash; schillbot_3000 (@schillbot3000) <a href="https://twitter.com/schillbot3000/status/1132499163252314112?ref_src=twsrc%5Etfw">May 26, 2019</a></blockquote><script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script><blockquote class="twitter-tweet"><p lang="en" dir="ltr">&quot;i am committed to doing everything in my power to cushion the impact of this great university&quot; <a href="https://t.co/WnfYOHRvLG">https://t.co/WnfYOHRvLG</a></p>&mdash; schillbot_3000 (@schillbot3000) <a href="https://twitter.com/schillbot3000/status/1181295022538280960?ref_src=twsrc%5Etfw">October 7, 2019</a></blockquote><script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script><blockquote class="twitter-tweet"><p lang="en" dir="ltr">&quot;please join me in this effort to address these issues as i apologize.&quot; <a href="https://t.co/WnfYOHRvLG">https://t.co/WnfYOHRvLG</a></p>&mdash; schillbot_3000 (@schillbot3000) <a href="https://twitter.com/schillbot3000/status/1181706316303101952?ref_src=twsrc%5Etfw">October 8, 2019</a></blockquote><script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script><blockquote class="twitter-tweet"><p lang="en" dir="ltr">&quot;over the past several months, we have experienced enormous churn in our boys by opening the doors of establish world-class research&quot; <a href="https://t.co/WnfYOHRvLG">https://t.co/WnfYOHRvLG</a></p>&mdash; schillbot_3000 (@schillbot3000) <a href="https://twitter.com/schillbot3000/status/1187033715743981568?ref_src=twsrc%5Etfw">October 23, 2019</a></blockquote><script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script><blockquote class="twitter-tweet"><p lang="en" dir="ltr">&quot;i am announcing these decisions now because i am not know the victim or the pain they will be doing&quot; <a href="https://t.co/WnfYOHRvLG">https://t.co/WnfYOHRvLG</a></p>&mdash; schillbot_3000 (@schillbot3000) <a href="https://twitter.com/schillbot3000/status/1132549248413650946?ref_src=twsrc%5Etfw">May 26, 2019</a></blockquote><script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script><blockquote class="twitter-tweet"><p lang="en" dir="ltr">&quot;i can go on to become one of the reasons why the university athletic fields will be in command of our state.&quot; <a href="https://t.co/WnfYOHRvLG">https://t.co/WnfYOHRvLG</a></p>&mdash; schillbot_3000 (@schillbot3000) <a href="https://twitter.com/schillbot3000/status/1180510220260274176?ref_src=twsrc%5Etfw">October 5, 2019</a></blockquote><script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script><blockquote class="twitter-tweet"><p lang="en" dir="ltr">&quot;during the summer months of that year, president michael schill shared his thoughts on the university&#39;s priorities: hard rock, my website&quot; <a href="https://t.co/WnfYOHRvLG">https://t.co/WnfYOHRvLG</a></p>&mdash; schillbot_3000 (@schillbot3000) <a href="https://twitter.com/schillbot3000/status/1183827424758288385?ref_src=twsrc%5Etfw">October 14, 2019</a></blockquote><script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script><h2 id="red-eyes-on-statues-20190803">red eyes on statues (2019.08.03)</h2><p>A good friend sent me this:</p><p><img src="/blog/assets/images/artvol2/redeyes_inspo.png" alt="redeyes inspo" /></p><p>So I copied it.</p><p>First I made some led-bombs by rigging them up to a 9V battery w/ a photodiode that turns the light off during the day to make them last longer.</p><video controls="" preload="none" style="max-height: 70vh;"> <source src="/blog/assets/images/artvol2/redeyes_prototype.mp4" type="video/mp4" /> </video><p>Then I attached them to a few statues around UO. I didn’t really photograph or catch much video of this because I was basically in a fugue state from being deliriously heartbroken and it was maybe a little bit of vandalism.</p><video controls="" preload="none"> <source src="/blog/assets/images/artvol2/redeyes_install.mp4" type="video/mp4" /> </video><h1 id="design">Design</h1><h2 id="autopilot-20191017">Autopilot (2019.10.17)</h2><p>I released some <a href="https://auto-pi-lot.com">software</a> and wrote a <a href="https://www.biorxiv.org/content/10.1101/807693v1">paper</a> to describe it, and I spent a lot of time to make a beautiful document. Typography is another art I am working to get better at, and I don’t really want to clutter up this post with a million page excerpts, but I am very proud of the way the figures are integrated with the text.</p><p>I will include the documentation logo that I like a lot though.</p><video controls="" preload="none"> <source src="/blog/assets/images/artvol2/autopilot_logo_loop.mp4" type="video/mp4" /> </video><h2 id="union-propaganda">Union Propaganda</h2><p>I don’t contribute enough to my union, but the one thing that I do contribute is a bit of design. These were all made during our most recent round of bargaining, which revealed what an amoral disaster of an institution the University of Oregon is.</p><h3 class="no_toc" id="uohellnocom">uohellno.com</h3><p>This was the website linked to by the schillbot. It works pretty badly on mobile (it was my first d3 scroller), so it will probably work even worse in this little iframe. may just want to visit <a href="https://uohellno.com">uohellno.com</a></p><p><a data-fancybox="" data-type="iframe" href="https://uohellno.com" class="iframe-preview">Open demo</a></p><h3 class="no_toc" id="salaries">Salaries</h3><p>Data available here: <a href="https://github.com/sneakers-the-rat/uoregon_salary_data">https://github.com/sneakers-the-rat/uoregon_salary_data</a></p><p><img src="/blog/assets/images/artvol2/gtff_salary.png" alt="UO exec salary nonsense" /></p><h3 class="no_toc" id="uoregons-healthcare-swindle">UOregon’s Healthcare Swindle</h3><p><img src="/blog/assets/images/artvol2/gtff_longterm.png" alt="longterm insurance costs" /></p><h1 id="stupid-bullshit-projects">stupid bullshit projects</h1><p>And finally, a bunch of other assorted scraps and pieces presented more or less without comment.</p><p><img src="/blog/assets/images/artvol2/the_great_bumblefuck.png" alt="talking 2 people" /></p><p>My department does “bullshit research talks” at our retreats, where someone makes a ridiculous presentation and someone else has to present it. Having someone I look up to very much present this neural-net face swap was one of my finest moments.</p><p><img src="/blog/assets/images/artvol2/matt_yashar_slide.png" alt="matt yashar slide" /></p><p><img src="/blog/assets/images/artvol2/matt_yashar_presentation.jpg" alt="matt yashar morph presentation" /></p><p><img src="/blog/assets/images/artvol2/dolphen.jpg" alt="dolphen" /></p><p>someone I love very much loves Selena very much, so this was for them.</p><p><img src="/blog/assets/images/artvol2/selena_centaur.png" alt="selena centaur" /></p><p><img src="/blog/assets/images/artvol2/MRPEANUT.png" alt="mr peanut" /></p><p><img src="/blog/assets/images/artvol2/heavy_breathing.jpg" alt="heavy breathing" /></p><p><img src="/blog/assets/images/artvol2/eurovision_heatmap.png" alt="eurovision heatmap" /></p><video controls="" preload="none" style="max-height: 70vh;"> <source src="/blog/assets/images/artvol2/goyles.mp4" type="video/mp4" /> </video><p>This was a gift I made for a dear dear friend that I unfortunately didn’t ever take a photo of the finished version. These panels stack together and have a few very fond memories in them. In this image: She is the sun, and i am the moon. one of the first memories I have with her is drunkenly fucking up someone else’s car radio (and it also fit iwth the scene), and nowadays I don’t see her much in part because she is busy all over the world &lt;3.</p><p><img src="/blog/assets/images/artvol2/jackie_gift.jpg" alt="jackie's gift" /></p><p><img src="/blog/assets/images/artvol2/pitchforkyrnose7.png" alt="pitchfork yr nose" /></p><p>Another dear dear friend got married last summer, and her maid of honor asked us to bring a photo of us together to their wedding. Shitty photoshop, but shitty photoshops are sorta one of the things we have a deep and shared love for.</p><p><img src="/blog/assets/images/artvol2/kris_faceswapped.png" alt="matt yashar morph presentation" /></p></div><ul class="post__social"><li><a href="https://www.facebook.com/sharer/sharer.php?u=https://jon-e.net/blog/2020/03/29/Past-Art-Vol-2/" target="_blank"><i class="fa fa-facebook"></i></a></li><li><a href="https://twitter.com/intent/tweet?&text=Past Art Vol 2: About a Year of It+https://jon-e.net/blog/2020/03/29/Past-Art-Vol-2/+by+Jonny Saunders" target="_blank"><i class="fa fa-twitter"></i></a></li><li><a href="https://plus.google.com/share?url=https://jon-e.net/blog/2020/03/29/Past-Art-Vol-2/" target="_blank"><i class="fa fa-google-plus"></i></a></li><li><a href="https://www.linkedin.com/shareArticle?mini=true&source=Past Art Vol 2: About a Year of It&summary=Collecting the scraps from about a year of wasting my time&url=https://jon-e.net/blog/2020/03/29/Past-Art-Vol-2/" target="_blank"><i class="fa fa-linkedin"></i></a></li><li><a href="https://www.stumbleupon.com/badge/?url=https://jon-e.net/blog/2020/03/29/Past-Art-Vol-2/" target="_blank"><i class="fa fa-stumbleupon"></i></a></li><li><a href="https://www.reddit.com/submit?url=https://jon-e.net/blog/2020/03/29/Past-Art-Vol-2/" target="_blank"><i class="fa fa-reddit-alien"></i></a></li><li><a href="https://www.tumblr.com/share/link?url=https://jon-e.net/blog/2020/03/29/Past-Art-Vol-2/" target="_blank"><i class="fa fa-tumblr"></i></a></li><li><a href="https://www.pinterest.com/pin/create/link/?description=Collecting the scraps from about a year of wasting my time&media=https://jon-e.net/blog/blog/assets/images/artvol2/endless_love.png&url=https://jon-e.net/blog/2020/03/29/Past-Art-Vol-2/" target="_blank"><i class="fa fa-pinterest"></i></a></li></ul></div>--></div><div class="section-padding--none"><div class="grid"><hr class="sep"/></div></div><div class="section-padding"><div class="grid-small"> <span class="post__author">Posted by <a href="http://jon-e.net" title="More By Jonny Saunders">Jonny Saunders</a></span><p class="post__bio">bad at programming and neuroscience in beautiful Oregon.</p></div></div></article></div></main><footer class="footer section-padding"><div class="grid"><div class="subscribe" id="subscribe"><div class="subscribe__container"> <span class="subscribe__title">Subscribe</span><p class="subscribe__text">Get a weekly email of posts I’ve added to the site.</p><form method="POST" action="&amp;c=?" id="mc-signup" name="mc-embedded-subscribe-form" novalidate><div style="position: absolute; left: -5000px;" aria-hidden="true"> <input type="text" name="" tabindex="-1" value=""></div><div class="form-group"> <input id="mce-EMAIL" type="email" name="EMAIL" placeholder="Email Address"></div><div class="form__btn"> <input id="mc-submit" type="submit" value="Sign Up" name="subscribe"></div></form><p class="subscribe__error hidden"></p></div></div><hr class="sep--white"/><div class="footer__container"><ul class="footer__tags"><li><a class="footer__link" href="/blog/tag/science">Science</a></li><li><a class="footer__link" href="/blog/tag/art">Art</a></li><li><a class="footer__link" href="/blog/tag/glitch">Glitch</a></li><li><a class="footer__link" href="/blog/tag/bad_art">Bad_art</a></li><li><a class="footer__link" href="/blog/tag/video">Video</a></li></ul><ul class="footer__social"><li><a href="https://twitter.com/json_dirs" target="_blank"><i class="fa fa-twitter"></i></a></li><li><a href="https://github.com/sneakers-the-rat" target="_blank"><i class="fa fa-github"></i></a></li></ul></div></div></footer><section class="contact popup"><div class="popup__close"><div class="popup__exit"></div></div><div class="contact__container popup__container"><div class="contact__img"><figure class="absolute-bg" style="background-image: url(/blog/assets/images/profpic.jpg);"></figure></div><div class="contact__content"><div class="contact__mast section-padding--half"><div class="grid"><h2>Contact</h2></div></div><div class="section-padding--none"><hr class="sep"/></div><div class="contact__form section-padding--half"><div class="grid-xlarge"> <form id="form" class="form" action="https://formcarry.com/s/x7yoFO6sk0n" method="POST"><div class="form__subcontainer"><div> <label for="form-first-name">First Name</label> <input type="text" name="first-name" id="form-first-name" required></div><div> <label for="form-last-name">Last Name</label> <input type="text" name="last-name" id="form-last-name" required></div></div><div> <label for="form-email">E-Mail</label> <input type="email" name="email" id="form-email" required></div><div> <label for="form-message">Message</label> <textarea name="message" id="form-message" rows="3"></textarea></div><div class="form__submit"><div class="form__btn"> <input type="submit" value="Send"></div></div><p class="form__message"></p></form></div></div></div></div></section><script src="/blog/assets/js/app.min.js"></script></body></html>
  